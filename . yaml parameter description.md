### **Configuration File (`.yaml`) Parameter Specification (Final Version)**

```yaml
# ===================================================================
# Global Configuration (Global)
# General settings that affect the entire pipeline or multiple components.
# ===================================================================
Global:
  # --- Device & Performance Configuration ---
  use_gpu: false               # [boolean] Whether to use GPU for inference (affects detector and feature extractor). (Default: false)
  gpu_id: 0                    # [integer] Specifies the GPU device ID to use (if use_gpu: true). (Default: 0)
  gpu_mem: 4000                # [integer] Initial GPU memory (in MB) to allocate upon initialization. (Default: 4000)
  cpu_num_threads: 6           # [integer] Number of threads to use for inference in CPU mode. (Default: 6)
  enable_mkldnn: false         # [boolean] Whether to enable Intel MKL-DNN acceleration in CPU mode. (Default: false)
  use_tensorrt: false          # [boolean] Whether to attempt using NVIDIA TensorRT for optimization in GPU mode. (Default: false)
  use_fp16: false              # [boolean] Whether to enable FP16 half-precision computation in GPU (especially TensorRT) mode. (Default: false)
  # ir_optim, batch_size, run_mode: [Note] These three parameters are not parsed by the current C API library code; setting them will have no effect.

  # --- Model Paths & Core Parameters ---
  rec_inference_model_dir: ""  # [string] **(Required)** Path to the inference model directory for the image recognition (feature extraction) model.
  det_inference_model_dir: ""  # [string] Path to the inference model directory for the object detection model. If this is empty or not provided, the detector will be disabled.
  feature_dim: 0               # [integer] (Strongly recommended) The vector dimension of the feature extraction model's output. Must strictly match the dimension of the recognition model and any existing index files.
                               #           If set to 0 or not provided, the system will try to infer it from the model automatically, but this may cause errors when loading a mismatched old index.
  feature_norm: true           # [boolean] Whether to apply L2 normalization to the features output by the feature extractor. (Default: true)

  # --- Object Detector Parameters (used only when det_inference_model_dir is valid) ---
  image_shape: [3, 640, 640]   # [list[integer]] **(Required)** The logical input shape [C, H, W] for the detection model.
  threshold: 0.5               # [float] Confidence threshold for object detection results (0.0 ~ 1.0). (Default: 0.5)
  max_det_results: 10          # [integer] Maximum number of detection boxes to keep for a single image (after sorting by confidence). (Default: 10)
  label_list: ["object"]       # [list[string]] **(Required)** The list of class labels for the detection model. The order must be consistent with the model's training.

  # --- Recognition/Retrieval Result Post-processing ---
  rec_nms_threshold: 0.05      # [float] IoU threshold for NMS applied to recognition results in `search` mode (0.0 ~ 1.0).
                               #         (Note: The code is also compatible with the old typo `rec_nms_thresold`) (Default: 0.05)

  # --- Visualization Configuration (Optional) ---
  visualize_detection_results: false   # [boolean] Whether to generate and save visualization images of detection results. (Default: false)
  visualize_search_results: false      # [boolean] Whether to generate and save visualization images of recognition results. (Default: false)
  vis_det_show_label: true             # [boolean] Controls whether to display labels and scores for detection boxes. (Default: true)
  visualization_output_dir: "./shitu_vis_out" # [string] Directory path to save visualization result images. (Default: "./shitu_vis_out")
  det_font_scale: 0.5                  # [float] Font scale for text labels in visualized images. (Default: 0.5)
  det_thickness: 2                     # [integer] Line thickness for bounding boxes in visualized images. (Default: 2)
  det_font_thickness: 1                # [integer] Font thickness for text in detection result visualizations. (Default: 1)
  rec_font_thickness: 1                # [integer] Font thickness for text in recognition result visualizations. (Default: 1)
  vis_rec_use_label: true              # [boolean] In recognition visualization, true: show the real label, false: force display of "ID_xxx". (Default: true)
  freetype_font_path: ""               # [string] Path to a FreeType font file (e.g., "./simsun.ttc") to correctly display non-ASCII characters (like Chinese) in visualizations.

# ===================================================================
# Index Processing Configuration (IndexProcess)
# Used for build, search, and delete modes.
# ===================================================================
IndexProcess:
  index_dir: "./index/shitu_index"  # [string] **(Required)** Base path and name for the FAISS index file and label mapping file.
                                    #          The program will generate `<index_dir>.index` and `<index_dir>.label` files. (Default: "./index/shitu_index")
  index_method: "IDMap,Flat"        # [string] FAISS index factory string. "IDMap,..." is recommended to support deletion. (Default: "IDMap,Flat")
  metric_type: "L2"                 # [string] Vector similarity metric ("L2" or "IP"). Must match the feature extraction model. (Default: "L2")
  threshold: 0.5                    # [float] **Recognition score threshold** (0.0 ~ 1.0), used in `search` mode to filter low-score results before NMS. (Default: 0.5)
  use_detBuild: false               # [boolean] **Index Building Mode**. true: build index for each detected box; false: build index for the whole image. (Default: false)
  delimiter: "\t"                   # [string] Delimiter between the image path and label when reading the image list file in `build` mode.
                                    #          Supports single characters (' ', ',') or the special escape `\t` for a tab. (Default: "\t")

# ===================================================================
# Detection Model Pre-processing Configuration (DetPreProcess)
# **Required** (if the detector is enabled).
# Note: This entire section is passed directly to the underlying detector
# component. Its internal format (e.g., `DetResize`, `target_size`, etc.)
# must conform to that component's requirements.
# ===================================================================
DetPreProcess:
  transform_ops:
    - DetResize:
        target_size: [640, 640]
        keep_ratio: false
        interp: 2
    - DetNormalizeImage:
        is_scale: true
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
    - DetPermute: {}

# ===================================================================
# Recognition (Feature Extraction) Model Pre-processing (RecPreProcess)
# **Required**.
# Note: This entire section is passed directly to the underlying feature
# extractor component. Its internal format (e.g., `ResizeImage`, `size`,
# `NormalizeImage`, `scale`, etc.) must conform to that component's requirements.
# ===================================================================
RecPreProcess:
  transform_ops:
    - ResizeImage:
        size: 224
        interpolation: 1
    - NormalizeImage:
        scale: 0.00392157
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
        order: "chw"
    - CropImage:
        size: 224

# ===================================================================
# Model Post-processing Configuration (DetPostProcess / RecPostProcess)
# (Not used by the current C API library code, structure is preserved)
# ===================================================================
DetPostProcess: {}
RecPostProcess: {}
```

---

### **`.yaml` Example File (`config_final_example.yaml`)**

This example is based on the confirmed valid configuration you provided, with added comments and recommendations.

```yaml
# ===================================================================
# ShiTu SDK - Standard Configuration File
#
# Instructions:
# 1. Please replace the "Your..." placeholders with your actual model paths.
# 2. Ensure all file paths are correct relative to your program's working directory.
# 3. This configuration enables "Detection + Recognition" mode by default, using the CPU for inference.
# ===================================================================

# ===================================================================
# Global Configuration (Global)
# ===================================================================
Global:
  # --- Device & Performance Configuration ---
  use_gpu: false               # true: use GPU, false: use CPU
  gpu_id: 0                    # Effective only when use_gpu: true
  cpu_num_threads: 8           # Recommended to set to the number of physical CPU cores
  enable_mkldnn: true          # Recommended to enable for Intel CPUs in CPU mode
  use_tensorrt: false          # When use_gpu: true, you can try enabling this for higher performance
  use_fp16: false              # When use_tensorrt: true, you can try enabling this

  # --- Model Paths & Core Parameters ---
  # **Required** - Please replace with your model paths
  rec_inference_model_dir: "./models/YourRecModel_infer"
  det_inference_model_dir: "./models/YourDetModel_infer"

  # **Required** - Please set the correct dimension according to your recognition model
  feature_dim: 512
  feature_norm: true           # Apply L2 normalization to features, recommended when using IP metric

  # --- Detector Parameters ---
  image_shape: [3, 640, 640]   # Must match your detection model
  threshold: 0.5               # Detection confidence threshold
  max_det_results: 10          # Detect a maximum of 10 objects per image
  label_list: ["product"]      # Must strictly correspond to your detection model's labels

  # --- Recognition/Retrieval Post-processing ---
  rec_nms_threshold: 0.1       # IoU threshold for merging recognition results

  # --- Visualization Configuration (for debugging and validation) ---
  visualize_detection_results: true   # Generate detection result images (_det_vis.jpg)
  visualize_search_results: true      # Generate recognition result images (_rec_vis.jpg)
  vis_det_show_label: false
  visualization_output_dir: "./output_vis"
  det_font_scale: 0.5
  det_thickness: 2
  det_font_thickness: 1
  rec_font_thickness: 1
  vis_rec_use_label: true
  # **Important**: If labels contain non-ASCII characters like Chinese, provide a valid font file path
  freetype_font_path: "./msyh.ttf" # Example: Windows "C:/Windows/Fonts/msyh.ttc"

# ===================================================================
# Index Processing Configuration (IndexProcess)
# ===================================================================
IndexProcess:
  # **Required** - Index files will be saved here
  index_dir: "./database/product_index"
  index_method: "IDMap,Flat"        # Exact index, supports deletion, suitable for small to medium datasets
  metric_type: "IP"                 # Inner Product / Cosine Similarity, used with normalized features
  threshold: 0.6                    # Recognition score threshold; results above this are considered valid
  use_detBuild: false               # **Index Building Mode**: 'true' builds the index for each detected box (not recommended).
  delimiter: "\t"                   # The list file for building the index uses Tab as a delimiter

# ===================================================================
# Detection Model Pre-processing Configuration (DetPreProcess)
# **Required** - Must be strictly consistent with the pre-processing used during your detection model's training
# ===================================================================
DetPreProcess:
  transform_ops:
    - DetResize:
        target_size: [640, 640]
        keep_ratio: false
        interp: 2
    - DetNormalizeImage:
        is_scale: true
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
    - DetPermute: {}

# ===================================================================
# Recognition (Feature Extraction) Model Pre-processing (RecPreProcess)
# **Required** - Must be strictly consistent with the pre-processing used during your recognition model's training
# ===================================================================
RecPreProcess:
  transform_ops:
    - ResizeImage:
        size: 224
        interpolation: 1
    - NormalizeImage:
        scale: 0.00392157 # 1.0/255.0
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
        order: "chw"
    - CropImage:
        size: 224

# ===================================================================
# Model Post-processing Configuration (Not used by the current C API library)
# ===================================================================
DetPostProcess: {}
RecPostProcess: {}
```

---

### **I. Global Configuration (Global Section)**

These parameters affect the overall runtime environment and the behavior of the core models.

1.  **Device & Performance (use_gpu, gpu_id, cpu_num_threads, etc.):**
    *   `use_gpu` (boolean, e.g., `true` / `false`): Whether to use the GPU for model inference.
    *   `gpu_id` (integer, e.g., `0`): If using GPU, specifies which GPU device to use.
    *   `cpu_num_threads` (integer, e.g., `12`): Specifies the number of threads to use for CPU inference.
    *   `enable_mkldnn` (boolean, e.g., `true` / `false`): Whether to enable MKLDNN acceleration for Intel CPUs (requires PaddlePaddle to be compiled with support).
    *   `use_tensorrt` (boolean, e.g., `true` / `false`): Whether to attempt using NVIDIA TensorRT for GPU inference acceleration (requires the model to support conversion and TensorRT to be installed in the environment).
    *   `use_fp16` (boolean, e.g., `true` / `false`): Whether to attempt using FP16 half-precision for inference (usually in conjunction with TensorRT or on specific hardware).
2.  **Model Paths & Core Attributes (det_inference_model_dir, rec_inference_model_dir, feature_dim):**
    *   `det_inference_model_dir` (string, e.g., `"./models/PP-ShiTuV2_det"`): Directory path for the **object detection model**. If this path is empty or invalid, the detector function will be disabled, and the API will only perform whole-image recognition and search.
    *   `rec_inference_model_dir` (string, e.g., `"./models/PP-ShiTuV2_rec"`): Directory path for the **recognition/feature extraction model**. **This parameter is required.**
    *   `feature_dim` (integer, e.g., `512`): **The feature vector dimension output by the recognition model.** If set to 0 or a negative number, the API will attempt to automatically get the dimension from the loaded recognition model. **It is strongly recommended** to set this parameter explicitly if the model dimension is known, to avoid auto-detection failures or inaccuracies. This dimension must match the recognition model and the index file (if loading an existing index).
3.  **Detector-Specific Parameters (effective only when `det_inference_model_dir` is valid):**
    *   `image_shape` (list of integers, e.g., `[3, 640, 640]`): The expected input image shape [C, H, W] (Channels, Height, Width) for the detection model. **Must strictly match the requirements of the chosen detection model.**
    *   `threshold` (float, e.g., `0.5`): The confidence threshold for the detector. Only detection boxes with a score higher than this threshold will be considered valid detections.
    *   `max_det_results` (integer, e.g., `5`): The maximum number of detection boxes to keep per image after the detection stage.
    *   `label_list` (list of strings, e.g., `["person", "car", "cat"]`): The list of class labels for the detection model. The order of strings in the list must strictly correspond to the class IDs (0, 1, 2...) output by the model. **This is very important when `use_detBuild: true` during index construction and you want to use the detector's classes as labels.**
4.  **Feature & Search Post-processing (feature_norm, rec_nms_threshold):**
    *   `feature_norm` (boolean, e.g., `true`): Whether to perform L2 normalization on the feature vector after extraction. If your recognition model already outputs normalized features (like PP-ShiTu models), setting this to `true` (harmless to re-normalize) or `false` is acceptable. If the model outputs non-normalized features and you want to use an index based on cosine similarity (inner product), this should be set to `true`.
    *   `rec_nms_threshold` (float, e.g., `0.1`): In search mode, this is the IoU threshold for Non-Maximum Suppression (NMS) used to merge overlapping recognition results from multiple candidate regions.

------

### **II. Index Processing Configuration (IndexProcess Section)**

These parameters control the construction, loading, saving, and search behavior of the index.

1.  **Index File & Construction Method (index_dir, index_method, metric_type):**
    *   `index_dir` (string, e.g., `"./product_index/all_products"`): The **base path and name** for the index file and the label mapping file. The API will append `.index` and `.label` suffixes to this path. **This parameter is required.**
    *   `index_method` (string, e.g., `"IDMap,Flat"` or `"IDMap,IVF1024,PQ16"`): The FAISS index factory string.
        *   `IDMap,Flat`: An exact index that supports deletion, suitable for small to medium-sized datasets.
        *   `IDMap,IVF...,PQ...`: An approximate index that supports deletion (due to `IDMap`), suitable for large-scale datasets. It uses clustering and quantization to speed up search at the cost of some precision.
    *   `metric_type` (string, `"L2"` or `"IP"`): The vector distance/similarity metric.
        *   `L2`: Euclidean distance.
        *   `IP`: Inner Product (dot product). Typically used with L2-normalized features to calculate cosine similarity.
2.  **Search & Build Parameters (threshold, delimiter, use_detBuild):**
    *   `threshold` (float, e.g., `0.6`): **Recognition score threshold**. In search mode, after extracting features for each candidate region (from the detector or the whole image) and comparing them with the index, a similarity score is obtained. Only candidate results with a score higher than this threshold will be considered for subsequent NMS processing.
    *   `delimiter` (string, e.g., `"\t"` or `" "`): In `build` mode, this is the character used to separate the image path and its label in the image list file. **It must exactly match the format of your list file.** (In YAML, a tab can be represented as `'\t'` or `"\\t"`).
    *   `use_detBuild` (boolean, e.g., `true` / `false`, defaults to `false`): **A key parameter that controls the index construction strategy.**
        *   `false` (default): Extracts the **whole-image** feature for each image in the list and builds the index. The ID is typically a simple auto-incrementing integer.
        *   `true`: First performs **object detection** on each image in the list, then extracts features for each detected **bounding box** and builds the index. The ID is often a composite ID (e.g., image line number + box index), and the label usually comes from the detector's class.

------

### **III. Pre-processing Configurations (DetPreProcess and RecPreProcess Sections)**

These two sections allow the user to define the detailed image pre-processing pipelines for the detection and recognition models.

*   **DetPreProcess:**
    *   `transform_ops`: (list): A sequence of operations that defines how to transform a raw input image into the format required by the detection model.
*   **RecPreProcess:**
    *   `transform_ops`: (list): A sequence of operations that defines how to transform a raw input image (or a detected ROI) into the format required by the recognition/feature extraction model.

**Each operation within the `transform_ops` list typically includes:**

*   **Operation Type as the Key:** e.g., `ResizeImage`, `NormalizeImage`, `Permute`, `CropImage`, `DetResize`, `DetNormalizeImage`, `DetPermute`, etc. (The specific names depend on your underlying pre-processing library, such as the operator names from PaddleClas/PaddleDetection).
*   **Operation Parameters as the Value:** e.g., `target_size: [640, 640]`, `keep_ratio: false`, `mean: [0.485, 0.456, 0.406]`, `std: [0.229, 0.224, 0.225]`, `order: "chw"`, etc.

**Demonstration of Flexibility:**

*   **Model Independence:** By modifying `*_model_dir`, `feature_dim`, `image_shape`, `label_list`, and the corresponding `DetPreProcess` and `RecPreProcess` sections, you can easily switch between different detection and recognition models without changing the C API library code.
*   **Performance Tuning:** You can adjust runtime performance using parameters like `use_gpu`, `cpu_threads`, `use_tensorrt`, and `use_fp16`.
*   **Indexing Strategy:** `index_method` and `metric_type` allow you to choose different index types based on dataset size and precision requirements. `use_detBuild` provides two fundamentally different granularities for index construction.
*   **Data Adaptability:** `delimiter` allows adaptation to different list file formats.
*   **Threshold Control:** Parameters like `threshold` (detection threshold), `max_det_results`, `rec_nms_threshold`, and `threshold` (recognition score threshold) allow you to fine-tune detection and search behavior to achieve a balance between recall and precision.

**Parameters Requiring Special Attention and Confirmation:**

*   All file and directory paths.
*   `feature_dim` must match the recognition model.
*   `image_shape` and `label_list` must match the detection model.
*   The `transform_ops` in `DetPreProcess` and `RecPreProcess` must strictly match the requirements of their respective models.
*   `IndexProcess.delimiter` must be consistent with the format of your build list file.
*   `metric_type` should be chosen based on whether features are normalized (`IP` for normalized features).